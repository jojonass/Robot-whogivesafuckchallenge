
Robot_main.py runs the main code for the control logic with a live robot, it will go through slides, incorporate both camera feeds, and use sequential logic to move along the steps of the assembly

Test_robot_control.py runs a mock simulation with live camera feeds to test logic 

action_chunks.py interfaces with urx to let you both create motion like linear motion and closing and opening the gripper, it also lets you to record multiple actions called chunks, 
these are saved on json file that can then be played back

gaze_tracking.py creates the gui needed for live webcame feed and recording, as well as allowing the division og gaze zones that help with control logic in Robot_main.py
This also contains the feature to control the number of cameras to be used and which camera IDS as well. 
Lets you switch between cameras. Also consider the zone division for a certain amount of delay.
Senitivity of the gaze detection direction as well as the zone division can be controlled 

Slides.py hosts the slides that create the Gui, these are then sequenced throuhg in the main loop, and contain the instructions of the assembly

gripper_trigger.py (Orange Detection + Pixel→Pose Conversion):
Provides the ObjectDetectionTrigger class.
It:
Detects an orange rectangle in the camera image
Waits until the object is held stable
Loads calibration values from camera_scales.npz
Converts pixel coordinates → millimeter offsets
Builds a full 6D UR robot pose relative to the TCP
Provides:
pose_D = detector.get_target_pose()

camera_scales.npz:
Generated by the calibration script.
Contains:
fx, fy, cx, cy
scale_x_mm_per_px
scale_y_mm_per_px
image_width, image_height
working distance (Z height)
Used during pixel → mm conversion to compute dynamic robot poses.

camera_calibration_pixelscale.py (Calibrate mm-per-pixel)
This script performs chessboard calibration using multiple images.
It computes:
Intrinsic matrix K
Distortion coefficients
Principal point cx, cy
Pixel → mm scaling at working height:
scale_x_mm_per_px
scale_y_mm_per_px
Everything is stored in:
camera_scales.npz
Used directly by gripper_trigger.py.

-----
Before Running the Full System
You must:
Calibrate the camera
python camera_calibration_pixelscale.py

Record all required robot chunks
python action_chunks.py

Start the main robot program
python Robot_main.py

------

Dependencies 
python 3.12 required
numpy
mediapipe
urx
opencv-python
streamlit
streamlit_autorefresh
pillow


